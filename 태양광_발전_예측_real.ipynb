{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "태양광 발전 예측_real.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sphuvz-DILxZ",
        "kHBXLsDO3vAr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimJae-hee/solar_panel/blob/master/%ED%83%9C%EC%96%91%EA%B4%91_%EB%B0%9C%EC%A0%84_%EC%98%88%EC%B8%A1_real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m4h9_w74uzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6T2-iEj5WyW",
        "colab_type": "text"
      },
      "source": [
        "### 우선 One-Hot Encoding으로 진행하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLQHYr3W4y-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sun = pd.read_csv('/content/drive/My Drive/P-SAT/태양광 예측/진짜 데이터 셋/final_data0723_3.csv', encoding = 'CP949')\n",
        "sun = sun.dropna(axis = 0)\n",
        "sun[\"ymd\"] = pd.to_datetime(sun[\"ymd\"], format = \"%Y-%m-%d\")\n",
        "y = sun[\"y\"]\n",
        "y.index = sun[\"ymd\"]\n",
        "del sun[\"y\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0LRFNV_52uV",
        "colab_type": "text"
      },
      "source": [
        "### 인코딩 해야 하는 변수 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTt3nzm75WKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cate_list = [\"month\", \"rain_type\", \"skycondition\", \"pm10_cat\", \"pm2_5_cat\", \"rain_yn\", \"hour\" ]\n",
        "sun_columns = sun.columns.values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9IVIJEg8Qkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_cate_list = sun_columns\n",
        "for i in range(len(cate_list)):\n",
        "  non_cate_list.remove(cate_list[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPmtFM_z55JP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sun_cat = sun[cate_list]\n",
        "sun_notcat= sun[non_cate_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szWUyx9WD6cT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del sun_notcat[\"day\"]\n",
        "del sun_notcat[\"wday\"]\n",
        "del sun_notcat[\"date\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53wgLwRz-dCs",
        "colab_type": "text"
      },
      "source": [
        "### 범주형 변수 One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVu33hX1-biQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(sun_cat)\n",
        "sun_cat_ohe = enc.transform(sun_cat).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCwm--TaIvYj",
        "colab_type": "text"
      },
      "source": [
        "### 범주형 변수 Ordinal Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AX-8ETxIzDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = OrdinalEncoder()\n",
        "enc.fit(sun_cat)\n",
        "sun_cat_ord = enc.transform(sun_cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYDm8wb7KSbo",
        "colab_type": "text"
      },
      "source": [
        "### 범주형 변수 Mean Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn_kR_UIKWrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def target_encoder(df, column, target, index=None, method='mean'):\n",
        "    \"\"\"\n",
        "        df (pandas df): Pandas DataFrame containing the categorical column and target.\n",
        "        column (str): Categorical variable column to be encoded.\n",
        "        target (str): Target on which to encode.\n",
        "        index (arr): Can be supplied to use targets only from the train index. Avoids data leakage from the test fold\n",
        "        method (str): Summary statistic of the target. Mean, median or std. deviation.\n",
        "    Returns:\n",
        "        arr: Encoded categorical column.\n",
        "    \"\"\"\n",
        "\n",
        "    index = df.index if index is None else index # Encode the entire input df if no specific indices is supplied\n",
        "\n",
        "    if method == 'mean':\n",
        "        encoded_column = df[column].map(df.iloc[index].groupby(column)[target].mean())\n",
        "    elif method == 'median':\n",
        "        encoded_column = df[column].map(df.iloc[index].groupby(column)[target].median())\n",
        "    elif method == 'std':\n",
        "        encoded_column = df[column].map(df.iloc[index].groupby(column)[target].std())\n",
        "    else:\n",
        "        raise ValueError(\"Incorrect method supplied: '{}'. Must be one of 'mean', 'median', 'std'\".format(method))\n",
        "\n",
        "    return encoded_column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et1k0lN-CfmQ",
        "colab_type": "text"
      },
      "source": [
        "### 다시 데이터 프레임 합치기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7icRwH8Dwob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(sun_notcat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InHP5j57D2bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.hstack((x, sun_cat_ohe))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-jUcPrFy0sD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e7c18a9b-385b-4a07-fa5c-ce1022ab0884"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8665, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WC6HjxIF00z",
        "colab_type": "text"
      },
      "source": [
        "### train, val, test set 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZRCm8DIF4iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "10dd343a-c268-4745-aeed-44c205307e70"
      },
      "source": [
        "x_train_1 = x[x[:,6] <= pd.to_datetime(\"2020-01-23\", format = \"%Y-%m-%d\")]\n",
        "x_train_2 = x[x[:,6] <= pd.to_datetime(\"2020-03-23\", format = \"%Y-%m-%d\")]\n",
        "x_train_3 = x[x[:,6] <= pd.to_datetime(\"2020-05-23\", format = \"%Y-%m-%d\")]\n",
        "\n",
        "x_val_1 = x[(x[:,6] >= pd.to_datetime(\"2020-01-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-01-30\", format = \"%Y-%m-%d\"))]\n",
        "x_val_2 = x[(x[:,6] >= pd.to_datetime(\"2020-03-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-03-30\", format = \"%Y-%m-%d\"))]\n",
        "x_val_3 = x[(x[:,6] >= pd.to_datetime(\"2020-05-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-05-30\", format = \"%Y-%m-%d\"))]\n",
        "\n",
        "# x_test_1 = x[x[:,6] == pd.to_datetime(\"2020-01-31\", format = \"%Y-%m-%d\")]\n",
        "# x_test_2 = x[x[:,6] == pd.to_datetime(\"2020-03-31\", format = \"%Y-%m-%d\")]\n",
        "# x_test_3 = x[x[:,6] == pd.to_datetime(\"2020-05-31\", format = \"%Y-%m-%d\")]\n",
        "\n",
        "y_train_1 = y[x[:,6] <= pd.to_datetime(\"2020-01-23\", format = \"%Y-%m-%d\")]\n",
        "y_train_2 = y[x[:,6] <= pd.to_datetime(\"2020-03-23\", format = \"%Y-%m-%d\")]\n",
        "y_train_3 = y[x[:,6] <= pd.to_datetime(\"2020-05-23\", format = \"%Y-%m-%d\")]\n",
        "\n",
        "y_val_1 = y[(x[:,6] >= pd.to_datetime(\"2020-01-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-01-30\", format = \"%Y-%m-%d\"))]\n",
        "y_val_2 = y[(x[:,6] >= pd.to_datetime(\"2020-03-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-03-30\", format = \"%Y-%m-%d\"))]\n",
        "y_val_3 = y[(x[:,6] >= pd.to_datetime(\"2020-05-24\", format = \"%Y-%m-%d\")) & (x[:,6] <= pd.to_datetime(\"2020-05-30\", format = \"%Y-%m-%d\"))]\n",
        "\n",
        "# y_test_1 = y[x[:,6] == pd.to_datetime(\"2020-01-31\", format = \"%Y-%m-%d\")]\n",
        "# y_test_2 = y[x[:,6] == pd.to_datetime(\"2020-03-31\", format = \"%Y-%m-%d\")]\n",
        "# y_test_3 = y[x[:,6] == pd.to_datetime(\"2020-05-31\", format = \"%Y-%m-%d\")]\n",
        "\n",
        "sum_y_val_1 = y_val_1.groupby(\"ymd\").sum()\n",
        "sum_y_val_2 = y_val_2.groupby(\"ymd\").sum()\n",
        "sum_y_val_3 = y_val_3.groupby(\"ymd\").sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-308-f1154c652f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2020-01-23\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_train_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2020-03-23\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_train_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2020-05-23\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_val_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2020-01-24\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2020-01-30\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/tslibs/c_timestamp.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.c_timestamp._Timestamp.__richcmp__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>=' not supported between instances of 'Timestamp' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTVwOOwJj0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delete_timestamp(x):\n",
        "  result = np.delete(x, 6, 1)\n",
        "  return result\n",
        "x_train_1 = delete_timestamp(x_train_1)\n",
        "x_train_2 = delete_timestamp(x_train_2)\n",
        "x_train_3 = delete_timestamp(x_train_3)\n",
        "\n",
        "# x_test_1 = delete_timestamp(x_test_1)\n",
        "# x_test_2 = delete_timestamp(x_test_2)\n",
        "# x_test_3 = delete_timestamp(x_test_3)\n",
        "\n",
        "x_val_1 = delete_timestamp(x_val_1)\n",
        "x_val_2 = delete_timestamp(x_val_2)\n",
        "x_val_3 = delete_timestamp(x_val_3)\n",
        "\n",
        "x_train_1 = np.array(x_train_1)\n",
        "x_train_2 = np.array(x_train_2)\n",
        "x_train_3 = np.array(x_train_3)\n",
        "\n",
        "x_val_1 = np.array(x_val_1)\n",
        "x_val_2 = np.array(x_val_2)\n",
        "x_val_3 = np.array(x_val_3)\n",
        "\n",
        "y_val_1 = np.array(y_val_1)\n",
        "y_val_2 = np.array(y_val_2)\n",
        "y_val_3 = np.array(y_val_3)\n",
        "\n",
        "y_train_1 = np.array(y_train_1)\n",
        "y_train_2 = np.array(y_train_2)\n",
        "y_train_3 = np.array(y_train_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiwGyWBV8KIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_set_list = [[x_train_1, y_train_1, x_val_1, y_val_1],\n",
        "                 [x_train_3, y_train_2, x_val_2, y_val_2],\n",
        "                 [x_train_2, y_train_3, x_val_3, y_val_3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GLt-IA5F5Qo",
        "colab_type": "text"
      },
      "source": [
        "### 손실함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-Wf58DOFtIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lossloss(y, y_hat):\n",
        "  result = []\n",
        "  for i in range(round(y.shape[0]/24)-1):\n",
        "    idx = range((24*i-23), (24*i))\n",
        "    tmp = sum(abs(y[idx] - yhat_val_1[idx])*y_val_1[idx])/sum(y_val_1[idx])/133\n",
        "    result.append(tmp)\n",
        "  loss = np.mean(result)\n",
        "  return loss\n",
        "\n",
        "def RMSE(y, y_hat):\n",
        "  result = mse(y, y_hat)**0.5\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sphuvz-DILxZ",
        "colab_type": "text"
      },
      "source": [
        "### data set1(2020년 01월 31일 예측) 모델 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5BGtautISUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim_x_train_1 = x_train_2.shape\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim= dim_x_train_1[1], activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n",
        "              metrics =[\"mse\"])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "hist = model.fit(x_train_2, y_train_2, epochs=300, batch_size=16, validation_split = 0.2,verbose=2, callbacks=[mc, early_stopping])\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.ylim(0, 20)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHBXLsDO3vAr",
        "colab_type": "text"
      },
      "source": [
        "### validation 데이터 예측 및 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW4ZF3VqNurZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ad126969-78dc-428c-f170-c85edb3f3c16"
      },
      "source": [
        "yhat_val_2 = model.predict(x_val_2)\n",
        "yhat_val_2 = yhat_val_2.flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ZSpuRhzUkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c96965aa-7f22-4125-8e3d-e7bd691cd100"
      },
      "source": [
        "print(RMSE(y_val_2, yhat_val_2))\n",
        "print(lossloss(y_val_2, yhat_val_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.503781143226856\n",
            "0.24362187869337018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A_-4AbpGX_F",
        "colab_type": "text"
      },
      "source": [
        "### 일반화 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQf_ME2PGdJb",
        "colab_type": "text"
      },
      "source": [
        "### 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq9S67pOGgBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim_x_train_1 = x_train_1.shape\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "# 2. 모델 구성하기\n",
        "amodel = Sequential()\n",
        "amodel.add(Dense(1, input_dim= dim_x_train_1[1], activation='relu'))\n",
        "amodel.add(Dense(30, activation='relu'))\n",
        "amodel.add(Dropout(0.3))\n",
        "amodel.add(Dense(20, activation='relu'))\n",
        "amodel.add(Dropout(0.3))\n",
        "amodel.add(Dense(10, activation='relu'))\n",
        "amodel.add(Dropout(0.3))\n",
        "amodel.add(Dense(1))\n",
        "# 3. 모델 학습과정 설정하기\n",
        "amodel.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n",
        "              metrics =[\"mse\"])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRyMlA2y_g2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 세트 리스트\n",
        "data_set_list = [[x_train_1, y_train_1, x_val_1, y_val_1],\n",
        "                 [x_train_2, y_train_2, x_val_2, y_val_2],\n",
        "                 [x_train_3, y_train_3, x_val_3, y_val_3]]\n",
        "\n",
        "# 모델링 함수 \n",
        "def modeling(train_x, train_y, val_x, val_y, amodel):\n",
        "  fitting = amodel.fit(train_x, train_y, epochs = 300, batch_size = 64, validation_split = 0.3, verbose = 0, callbacks = [mc, early_stopping] )\n",
        "\n",
        "  # validation set 예측  \n",
        "  y_hat = amodel.predict(val_x)\n",
        "  y_hat = y_hat.flatten()\n",
        "\n",
        "  # 평가지표 산출 \n",
        "  weighted_mean = lossloss(val_y, y_hat)\n",
        "  rmse = RMSE(val_y, y_hat)\n",
        "\n",
        "  return weighted_mean, rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5OuoYZCAO7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "64579b3b-4541-4c72-a29c-0f8c0d94ae72"
      },
      "source": [
        "weighted = []\n",
        "rmse = []\n",
        "for i in range(len(data_set_list)):\n",
        "  X_train = data_set_list[i][0]\n",
        "  Y_train = data_set_list[i][1]\n",
        "  X_val = data_set_list[i][2]\n",
        "  Y_val = data_set_list[i][3]\n",
        "  tmp_weighted, tmp_rmse = modeling(X_train, Y_train, X_val, Y_val, amodel)\n",
        "  \n",
        "  weighted.append(tmp_weighted)\n",
        "  rmse.append(tmp_rmse)\n",
        "\n",
        "  print(i, \"번째 validiaion 결과는 다음과 같습니다.\", \":::\", \"가중평균: \", tmp_weighted, \"RMSE: \", tmp_rmse )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00216: early stopping\n",
            "0 번째 validiaion 결과는 다음과 같습니다. ::: 가중평균:  0.08909270690386133 RMSE:  10.423866573762693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-311-c6786274f017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mY_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_set_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtmp_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mweighted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_weighted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-310-16b30aa2393b>\u001b[0m in \u001b[0;36mmodeling\u001b[0;34m(train_x, train_y, val_x, val_y, amodel)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 모델링 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mfitting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# validation set 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3C6_6UJEyRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7c37d745-4310-4cb8-84f6-f3d0b8bc893c"
      },
      "source": [
        "print(\"rmse 평균은\", np.mean(rmse), \"\\n\", \"가중평균은\", np.mean(weighted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rmse 평균은 15.555703874316322 \n",
            " 가중평균은 0.1900217844404515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMuPUm8TAhe-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3c47c568-9393-4a88-caa8-a4c7d22fd650"
      },
      "source": [
        "for i in range(len(data_set_list)):\n",
        "  X_train = data_set_list[i][0]\n",
        "  Y_train = data_set_list[i][1]\n",
        "  X_val = data_set_list[i][2]\n",
        "  Y_val = data_set_list[i][3]\n",
        "  print(X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4944, 57) (4944,) (168, 57) (168,)\n",
            "(7800, 57) (6360,) (168, 57) (168,)\n",
            "(6360, 57) (7800,) (168, 57) (168,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGp18-NQR7WV",
        "colab_type": "text"
      },
      "source": [
        "# 어디선가 변수명 설정이 잘못되어 모델이 업데이트 되지 않고 있다. 그로인해 지금 결과값이 변하질 않는다... 보고 수정하자 다음에 ㅠ\n"
      ]
    }
  ]
}